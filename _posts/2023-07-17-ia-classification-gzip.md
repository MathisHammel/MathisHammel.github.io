---
layout: post
title:  "Ce programme de 15 lignes rivalise avec les meilleures IA !"
date:   2023-07-17 13:25:38 +0200
image:  '/images/blog/ia-classification-gzip/header.png'
tags:   [IA, Algo]
---

Un programme de 15 lignes de code Python arrive √† rivaliser avec les meilleures intelligences artificielles !

Cette dr√¥le de d√©couverte vient d'√™tre publi√©e par une √©quipe de chercheurs canadiens, et risque de bouleverser le monde du Machine Learning.

Explications ‚§µÔ∏è 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901570156806145-F1O_BqwWIAAE4Wz.jpg" draggable="false">
  </div>
</div>

La **classification de texte** est l'un des domaines de recherche les plus actifs en intelligence artificielle : elle consiste √† trier automatiquement des textes courts dans un ensemble de cat√©gories pr√©-d√©finies. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901573931675648-F1O_XxpWIAAmGMR.jpg" draggable="false">
  </div>
</div>

Pour √©valuer la performance d'un mod√®le, on va travailler avec des datasets sp√©cifiques.

L'un des plus connus est bas√© sur 1.4 millions de questions pos√©es sur le site **Yahoo Answers**, r√©parties en 10 cat√©gories : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901577266085888-F1O_wGHWAAE5r_D.jpg" draggable="false">
  </div>
</div>

L'algorithme peut donc utiliser ces donn√©es pour apprendre √† quoi ressemblent les questions de chaque cat√©gorie.

On va ensuite le mettre √† l'√©preuve avec 60 000 questions non-√©tiquet√©es sur lesquelles il devra pr√©dire la cat√©gorie. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901580499869696-F1PAQm5WcAAmAon.jpg" draggable="false">
  </div>
</div>

Il existe plusieurs mani√®res de mesurer la performance d'un mod√®le de machine learning sur cette t√¢che.

La plus courante consiste √† simplement calculer le **taux de pr√©dictions correctes** : par exemple, un mod√®le qui donne 45k cat√©gories correctes sur les 60k textes aura un score de 75%.

Cette mesure est appel√©e l'accuracy, ou "pr√©cision" en fran√ßais.

Cependant, le mot fran√ßais est peu utilis√© car ambigu avec le terme anglais "precision" : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901587097509888-F1PAsRCWYAAnwLr.jpg" draggable="false">
  </div>
</div>

√Ä l'heure actuelle, parmi les mod√®les textuels les plus performants (dits "√† l'√©tat de l'art") on retrouve notamment BERT, publi√© en open source par Google en 2018.

C'est un mod√®le immense qui compte jusqu'√† **340 millions de neurones** !

Face √† ce titan, les chercheurs de l'universit√© de Waterloo ont donc d√©cid√© de cr√©er... un script tout simple de 15 lignes. Et √ßa a march√© üòÅ

Regardons de plus pr√®s son fonctionnement. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901592998879232-F1PBDx1XsAAfTZu.jpg" draggable="false">
  </div>
</div>

Dans l'algo pr√©sent√©, on rep√®re quelques op√©rations de la forme len(gzip.compress(x)) : c'est ici que se cache son secret. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901599462400003-F1O7we1WwAA7ISM.jpg" draggable="false">
  </div>
</div>

Gzip est un utilitaire de **compression de fichiers** bas√© sur le m√™me algorithme que pour les fichiers .zip : en trouvant des motifs qui se r√©p√®tent dans les donn√©es √† compresser, on va pouvoir r√©duire la taille du fichier sans perdre d'information. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901602494881792-F1O73brWwAAI48X.jpg" draggable="false">
  </div>
</div>

Et ce facteur de compression peut justement √™tre utilis√© pour mesurer la redondance d'information dans un texte !

J'ai compress√© 1000 caract√®res de la page Wikip√©dia "r√©seaux de neurones artificiels" et 1000 caract√®res al√©atoires, voici les r√©sultats respectifs : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901606282350592-F1O8JXOWIAAQb85.jpg" draggable="false">
  </div>
</div>

On peut donc constater qu'un texte en fran√ßais contient davantage de redondance (= moins d'entropie) qui permet de le compresser plus efficacement.

De m√™me, la concat√©nation de deux textes se compressera **plus facilement** si les deux textes sont similaires : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901610673958913-F1O8ShsWYAE1rVD.jpg" draggable="false">
  </div>
</div>

En se basant sur cette observation, on peut donc mettre en place un syst√®me capable de calculer une sorte de "**distance s√©mantique**" entre deux textes !

La formule ci-dessous est celle qui est utilis√©e par les chercheurs dans leur article : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901614033313794-F1O8ZJ4WwAI0x_L.jpg" draggable="false">
  </div>
</div>

Cette formule provient de concepts th√©oriques comme la distance de Kolmogorov conditionnelle et l'information algorithmique mutuelle.

S√ªrement des concepts invent√©s par les chercheurs pour se la p√©ter en soir√©e, mais je vais vous montrer qu'on peut la comprendre facilement. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901616864489475-F1O8f-wXsAEC_hc.jpg" draggable="false">
  </div>
</div>

Consid√©rons que l'on veut comparer la similarit√© de deux textes x1 et x2. On note C(x) la taille d'un texte x apr√®s compression.

Pour simplifier les choses, on va dire que la distance est comprise entre 0 et 1, et que C(x1)‚â•C(x2).

Penchons-nous sur deux cas extr√™mes :

### Cas 1

x1 et x2 sont **extr√™mement similaires** : les infos de x2 sont enti√®rement contenues dans x1.

Ajouter x2 apr√®s x1 ne change pas la taille du fichier compress√©.

Les deux textes sont tr√®s proches, on souhaite donc que leur distance soit 0. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901621503475713-F1O8sIYXoAA6yTI.jpg" draggable="false">
  </div>
</div>

### Cas 2

x1 et x2 sont **radicalement diff√©rents** : compresser x1+x2 ensemble ne permettra pas de gagner de place par rapport √† la compression des deux textes s√©par√©ment.

Ici, on veut donner une distance √©lev√©e (donc 1) √† cette paire de textes. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901624712003587-F1O9ahPWwAA9W47.jpg" draggable="false">
  </div>
</div>

Bien s√ªr, ces deux cas sont extr√™mes et ne se produisent pas en pratique, mais √† l'aide de ces deux points de r√©f√©rence il est maintenant possible de mettre en place une fonction affine qui donne la distance en fonction de C(x1+x2) : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901627950104576-F1O9g0eXgAEj5zy.jpg" draggable="false">
  </div>
</div>

L'√©quation de la droite ci-dessus correspond en fait exactement √† celle utilis√©e par les chercheurs de l'universit√© de Waterloo !

La seule diff√©rence est l'utilisation des fonctions min et max, qui permettent d'√©changer potentiellement x1 et x2 pour s'assurer que C(x1)‚â•C(x2). 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901631087345664-F1O9oE6WAAARvHS.jpg" draggable="false">
  </div>
</div>

Avec cette formule, on peut maintenant cr√©er un puissant classificateur : pour trouver la cat√©gorie d'un texte x1 inconnu, on va chercher le texte x2 parmi le dataset d'entra√Ænement qui s'en approche le plus.

Il est probable que la cat√©gorie de x1 soit la m√™me que x2. 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901634090516480-F1O9vt8XgAEVvo1.jpg" draggable="false">
  </div>
</div>

En pratique, les r√©sultats sont impressionnants : sur un benchmark comprenant 13 mod√®les r√©cents, cet algorithme parvient √† se classer sur le podium √† plusieurs reprises, et m√™me en premi√®re place sur de nombreux datasets non-anglais !

Et m√™me si BERT semble tout de m√™me plus efficace que notre technique magique √† base de gzip, cette derni√®re pr√©sente 3 avantages majeurs :

- Sa simplicit√© de mise en ≈ìuvre
- Aucun pr√©-entra√Ænement n√©cessaire
- Une bonne performance dans toutes les langues

Avant de terminer ce thread, je vous propose **deux petites curiosit√©s de code** li√©es √† ce papier.

La premi√®re est une erreur algorithmique que j'ai trouv√©e dans le code publi√© : un calcul pourrait √™tre optimis√©, voyez-vous lequel ? (indice : c'est dans les 3 derni√®res lignes) 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901642265194498-F1O-MC-WwAE3ltS.jpg" draggable="false">
  </div>
</div>

On peut constater ici que le code cherche les k textes les plus proches de chaque x1 dans le jeu d'entra√Ænement, puis trouve la cat√©gorie majoritaire parmi ceux-ci.

On appelle √ßa une recherche kNN (k Nearest Neighbors). Dans ce papier en particulier, les chercheurs prennent k=2.

Pour calculer les k plus proches voisins, l'impl√©mentation du papier de recherche va faire quelque chose comme √ßa (via numpy.argsort) : 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680901647159918594-F1O-ZYNXgAEDxBG.jpg" draggable="false">
  </div>
</div>

Cette op√©ration est en r√©alit√© tr√®s inefficace : on appelle une fonction de tri sur un tableau **gigantesque** (jusqu'√† 1,4 millions d'√©l√©ments pour le dataset Yahoo Answers), pour n'utiliser que les 2 premiers r√©sultats...

En utilisant un tas binaire, structure de donn√©es sp√©cialis√©e, on peut grandement am√©liorer la performance du calcul en ne gardant que les k meilleurs r√©sultats au fil de l'ex√©cution : la complexit√© temporelle de l'extraction passe de O(N¬∑log(N)) √† O(N¬∑log(k)). 

<div class="gallery-box">
  <div class="gallery">
  <img style="height:350px; object-fit:cover" src="/images/blog/ia-classification-gzip/1680902608393781249-F1PDYErXgAAYYla.jpg" draggable="false">
  </div>
</div>

Et en pratique ?

Sur le dataset Yahoo Answers, on atteint **un gain de performance de +16%** gr√¢ce √† mon optimisation, ce qui est loin d'√™tre n√©gligeable sur un benchmark qui demande 6 jours de calcul ! (La technique gzip est tr√®s lente car on doit calculer toutes les paires)

La seconde curiosit√© que je voulais vous montrer concerne la taille du code : c'est rare d'avoir un papier de recherche complet qui tient en 15 lignes de code, mais peut-on aller encore plus loin ?

En utilisant quelques techniques assez sales, j'ai r√©ussi √† faire passer le script de 538 √† 214 caract√®res (en ajoutant au passage mon optimisation algorithmique üòá)

Je vous pr√©sente le meilleur classifieur de texte au monde qui tient en un tweet :

```python
import gzip,heapq
g=lambda x:len(gzip.compress(x))
def classify(t):
 A=g(t)
 h=[(-1,)]*K
 for(a,b)in train:heapq.heappushpop(h,((min(A,g(a))-g(t+b' '+a))/max(A,g(a)),b))
 s=[x[1]for x in h]
 return max(set(s),key=s.count)
```

C'est la fin de l'article, merci d'avoir tenu jusqu'au bout !

Il aurait pu √™tre 2 fois plus court si je voulais aller droit au but, mais y'avait plein de petites digressions que je trouvais trop int√©ressantes. N'h√©sitez pas √† partager ‚ò∫Ô∏è

Et pour aller lire le papier de recherche complet, c'est par ici : [https://aclanthology.org/2023.fi...](https://aclanthology.org/2023.findings-acl.426.pdf)

**UPDATE :** Il semble que les benchmarks de ce papier ont √©t√© un peu bidouill√©s pour gonfler le score du classificateur gzip. L'enqu√™te de <a href="https://twitter.com/_kenschutte" target="_blank">@_kenschutte</a> est concordante avec les r√©sultats que je calcule en local : [https://kenschutte.com/gzip-knn-...](https://kenschutte.com/gzip-knn-paper/)

