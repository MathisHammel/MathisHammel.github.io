---
layout: post
title:  "Non, ChatGPT n'est pas devenu nul en maths"
date:   2023-07-22 13:35:38 +0200
image:  '/images/blog/chatgpt-performance-maths/header.png'
tags:   [IA]
---

ChatGPT est-il devenu nul en maths ?

Cette affirmation, basÃ©e sur une Ã©tude de **l'universitÃ© de Stanford**, est complÃ¨tement fausse. Je vous explique en 3 minutes. [https://twitter.com/Dexerto/stat...](https://twitter.com/Dexerto/status/1682441930637029376)

<blockquote class="twitter-tweet tw-align-center" data-conversation="none" data-dnt="true" data-theme="dark">
  <a href="https://twitter.com/Dexerto/status/1682441930637029376"></a>
</blockquote>

En cherchant les sources, on retrouve bien un papier de recherche qui montre **une chute de 97.6% Ã  2.4%** sur la performance de GPT-4.

Pour calculer ce score, les chercheurs ont posÃ© 500 questions Ã  ChatGPT de type **"est-ce que le nombre [X] est premier ?"**

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/chatgpt-performance-maths/1682716031070896129-F1o1UBlWIAI1pUH.jpg" draggable="false">
  </div>
</div>

Vous remarquerez d'ailleurs que sur le mÃªme laps de temps, on voit une nette amÃ©lioration de GPT-3.5 : c'est le modÃ¨le principal de ChatGPT, car la version avancÃ©e GPT-4 n'est dispo que pour les utilisateurs payants.

Mais bon, on sait bien que le clickbait Ã§a fait des vues ğŸ˜‡

La question reste tout de mÃªme lÃ©gitime : qu'est-ce qui peut expliquer de tels changements sur les performances ?

Pour son Ã©valuation, l'article de Stanford se base sur un autre papier de recherche paru en 2023. Voyons comment les 500 nombres ont Ã©tÃ© choisis : 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/chatgpt-performance-maths/1682716040252252161-F1o1UiBXoAAPsPi.jpg" draggable="false">
  </div>
</div>

Et voilÃ  l'arnaque : **on ne prÃ©sente Ã  ChatGPT que des nombres premiers**, donc la rÃ©ponse attendue sera toujours "oui" ğŸ™ƒ

Ce qui veut dire qu'un modÃ¨le YesGPT qui rÃ©pondrait "oui" Ã  n'importe quelle question obtiendrait **100%** Ã  ce test !

Voici par exemple la rÃ©ponse de GPT-3.5, censÃ© Ãªtre un champion des nombres premiers, quand je lui prÃ©sente le nombre 13747 (=59Ã—233).

Il fait semblant de vÃ©rifier tous les diviseurs, puis affirme sans aucune hÃ©sitation que 13747 est premier ğŸ˜… 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/chatgpt-performance-maths/1682716049546833922-F1o1VD9XgAETLiC.jpg" draggable="false">
  </div>
</div>

D'autres chercheurs ont reproduit l'Ã©tude avec des nombres composites (= non-premiers), et on constate une inversion quasi-parfaite des rÃ©sultats.

Ici, la conclusion est claire : **ChatGPT n'est pas devenu mauvais, il l'a toujours Ã©tÃ©** sur cette tÃ¢che ! 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/chatgpt-performance-maths/1682716055804817409-F1o1Va7WYAAyx2b.jpg" draggable="false">
  </div>
</div>

Je trouve Ã§a vraiment dommage que cette fausse information soit reprise massivement par des journalistes sans esprit critique, et sans consulter de spÃ©cialistes. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/chatgpt-performance-maths/1682716063094431749-F1o1V06X0AEVPNv.jpg" draggable="false">
  </div>
</div>

Une belle leÃ§on Ã  tirer de cette histoire : **si vous lisez "selon une Ã©tude de [insÃ©rer universitÃ© amÃ©ricaine ici]", vous avez 99% de chances de lire n'importe quoi.**

Ici, il aurait fallu dire "Ã©tude sans validation par peer-review, co-Ã©crite par un Ã©tudiant de Stanford". Pas ouf.

J'espÃ¨re que ce thread improvisÃ© vous aidera Ã  vous protÃ©ger contre les articles aux airs faussement scientifiques qui racontent n'importe quoi ğŸ˜‰

Et si l'IA vous intÃ©resse, voici un autre [article de vulgarisation](/blog/fonctionnement-dall-e-2) sur le fonctionnement de DALLÂ·E 2 qui pourrait vous plaire !

