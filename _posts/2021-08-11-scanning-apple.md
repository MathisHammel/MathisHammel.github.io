---
layout: post
title:  "Comment Apple pr√©voit de d√©tecter des photos ill√©gales sur votre iPhone"
date:   2021-08-11 20:22:40 +0200
image:  '/images/blog/scanning-apple/header.png'
tags:   [Algo, IA, Cybers√©curit√©, Cryptographie]
---

Cette semaine, Apple a annonc√© une nouvelle feature dans iOS 15 qui scannera l'album photo des utilisateurs d'iCloud √† la recherche de contenus p√©do-pornographiques.

J'ai √©tudi√© le protocole cryptographique sous-jacent, et je vous propose un article de vulgarisation. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523073806110720-E8hbOeNWQAQ-J41.png" draggable="false">
  <img src="/images/blog/scanning-apple/1425523073806110720-E8hbiZwWUAQ9RPg.png" draggable="false">
  </div>
</div>

Je me suis paluch√© la publication scientifique d'Apple, 32 pages de notation math√©matique assez touffue que je vais me charger de simplifier. Premi√®re surprise, le papier est co-√©crit par **Dan Boneh**, une pointure en cryptographie (membre √©m√©rite de l'IACR, prix G√∂del, ...) 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523078579331081-E8hcpp3WYAAQeUJ.png" draggable="false">
  </div>
</div>

Comme je le rappelais en r√©action √† un titre d'article un peu trop clickbait, la d√©tection se fait sur une liste de photos **pr√©-√©tablie** pour limiter au maximum le risque de faux positifs.

[https://twitter.com/MathisHammel...](https://twitter.com/MathisHammel/status/1423573926240739329)

<blockquote class="twitter-tweet tw-align-center" data-conversation="none" data-dnt="true" data-theme="dark">
  <a href="https://twitter.com/MathisHammel/status/1423573926240739329"></a>
</blockquote>

Le protocole est bien construit, il s'appuie sur trois composants principaux qui assurent une protection de la vie priv√©e, malgr√© cette intrusion assez directe dans les donn√©es perso. J'ai cependant identifi√© quelques probl√®mes sur lesquels je reviendrai en fin de thread.

N.B. : on ne se penchera pas sur le 2e m√©canisme de protection de l'enfance annonc√© par Apple, √† savoir la d√©tection de nudit√© dans les photos envoy√©es vers/depuis des appareils soumis au contr√¥le parental. Je n'ai pas la l√©gitimit√© d'expert en vie priv√©e pour cette analyse. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523089115426824-E8hdpPhWYA0GLUh.png" draggable="false">
  </div>
</div>

On va √©tudier dans trois mini-chapitres les composants du protocole d'Apple, qui ont chacun des propri√©t√©s tr√®s int√©ressantes.

### I. NEURALHASH 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523096245706757-E8hxFaHX0AI-3U0.jpg" draggable="false">
  </div>
</div>

NeuralHash est un algorithme de hachage d'images bas√© sur un r√©seau de neurones. Ici, pas question d'utiliser un hash cryptographique conventionnel comme SHA256, car il serait possible de contourner la d√©tection en modifiant un seul bit de l'image. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523101924794368-E8hfHMuWEAoecy1.png" draggable="false">
  </div>
</div>

Dans notre protocole, le r√©seau de neurones est entra√Æn√© pour cr√©er un **hash visuel** capable de "comprendre" la structure de l'information et donner le m√™me hash √† deux images visuellement identiques, tout en r√©sistant aux transformations comme l'ajout de bruit, le recadrage, la compression, ... 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523106832134149-E8hfkKlWUAIWOk8.jpg" draggable="false">
  </div>
</div>

Le r√©seau transforme une image en un vecteur de nombres. Le r√©seau est entra√Æn√© √† partir d'images d√©riv√©es d'un ensemble d'images de base. Il produit des vecteurs proches si les deux images ont la m√™me base, et √©loign√© sinon.

Tr√®s similaire √† word2vec pour ceux qui connaissent : 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523111596859393-E8hg7pLXIAM0bI0.png" draggable="false">
  </div>
</div>

Ce type de hachage existe d√©j√†, avec notamment **PhotoDNA** de Microsoft (qui a d'ailleurs √©t√© cr√©√© en 2009 pour combattre l'exploitation des mineurs).

J'utilise aussi ce type de r√©seau de neurones dans un outil que je d√©voilerai lors de ma prochaine conf√©rence, √† <a href="https://twitter.com/_barbhack_" target="_blank">@_barbhack_</a> ! üòá 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523116579635209-E8hhrIKX0AETHMC.jpg" draggable="false">
  </div>
</div>

Les NeuralHashs sont la base du syst√®me de d√©tection propos√©. Mais les hashs de vos photos ne sont pas transmis directement √† Apple pour comparaison avec la base de donn√©es d'images ill√©gales, ce serait une entorse au chiffrement end-to-end d'iCloud.

On en reparle au chapitre III üòâ

### II. THRESHOLD SECRET SHARING 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523123567403008-E8hijq4WUAElWkx.jpg" draggable="false">
  </div>
</div>

Le syst√®me de d√©tection d'images p√©do-pornographiques envoie √† Apple des m√©tadonn√©es sur les images d√©tect√©es. En cas de faux positif, Apple pourrait acc√©der aux m√©tadonn√©es correspondantes sans raison valable, et c'est pour cette raison qu'un seuil a √©t√© mis en place.

En dessous de N correspondances avec la base de donn√©es, un m√©canisme cryptographique (que les initi√©s voient venir d'apr√®s son nom) emp√™che de lire les m√©tadonn√©es. Le nombre N de correspondances n√©cessaires n'a pas √©t√© rendu public (je pense qu'il est entre 3 et 5).

Le principe sous-jacent au Threshold Secret Sharing ne date pas d'hier : en 1979, Adi Shamir (√©minent cryptologue, la lettre S du cryptosyst√®me RSA c'est lui) publie son "**Secret Sharing Scheme**" (SSS), qui permet de partager une donn√©e secr√®te de mani√®re tr√®s √©l√©gante. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523131242909698-E8hjiFUWYAk4CXm.png" draggable="false">
  </div>
</div>

Le SSS permet de d√©couper un nombre secret en plusieurs parts, de telle sorte que l'on peut reconstituer le secret d'origine seulement si l'on dispose d'**au moins K parts** (K est un param√®tre choisi lors de la cr√©ation des parts). On va prendre un petit exemple :

Quand je meurs, je veux que ma famille ait acc√®s √† mon compte Twitter pour continuer √† liker les tweets de <a href="https://twitter.com/plhery" target="_blank">@plhery</a>. Mais pas question de donner √† chacun mon mdp d√®s maintenant ! Je peux donc cr√©er des parts de mon mdp avec un seuil K=3, et j'en donne une √† chacun de mes proches. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523136590721026-E8hwJSaWEAI0Cbc.jpg" draggable="false">
  </div>
</div>

√Ä tout moment, il suffira que 3 de mes proches (peu importe lesquels) mettent leurs parts en commun et ils pourront **reconstituer le mdp**. SSS est beaucoup plus fort que de donner √† chacun quelques caract√®res du secret, car ici **n'importe quelle combinaison** de 3 parts fonctionne ! 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523141015740422-E8hrP0NWQAgzUeQ.jpg" draggable="false">
  </div>
</div>

Le syst√®me Threshold Secret Sharing fonctionne √† peu pr√®s de la m√™me mani√®re : pour chaque correspondance avec la base de donn√©es d'images ill√©gales, l'appareil fait remonter des m√©tadonn√©es qui sont chiffr√©es √† l'aide d'une cl√© g√©n√©r√©e par l'appareil de l'utilisateur. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523145092571143-E8hvqo2XEAQ1FJk.jpg" draggable="false">
  </div>
</div>

Apple n'a initialement pas cette cl√© et ne peut donc d√©chiffrer aucune m√©tadonn√©e. Par contre, avec chaque match remont√© est aussi fourni **un fragment SSS** de la cl√©. Apr√®s N rapports remont√©s, Apple peut donc reconstituer la cl√© et d√©chiffrer les m√©tadonn√©es associ√©es √† ceux-ci. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523149395963907-E8hwQbNXsAYkwZ4.jpg" draggable="false">
  </div>
</div>

Un autre m√©canisme permet aussi de cacher √† Apple le nombre exact de matchs : des matchs "synth√©tiques" contenant des faux fragments de cl√©s sont produits al√©atoirement par tous les appareils, et Apple n'a aucun moyen de distinguer les vrais des faux avant d'en poss√©der N vrais.

### III. PRIVATE SET INTERSECTION 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425523155343380481-E8hw1kJXIAIq9J1.jpg" draggable="false">
  </div>
</div>

Dans les deux pr√©c√©dents chapitres, on a √©tudi√© comment les images √©taient compar√©es de mani√®re fiable, et comment les matchs dans la base d'images √©taient masqu√©s avant d'avoir atteint un seuil. Mais le vrai coeur du protocole c'est PSI, ou **Private Set Intersection**.

Il y a plusieurs consid√©rations √† prendre en compte :

- Apple ne veut pas d√©voiler la liste d'images recherch√©es (s√ªrement pour √©viter les contournements)
- On ne doit pas divulguer √† Apple la moindre info sur les images non-ill√©gales d'un utilisateur, pas m√™me leur NeuralHash

Ce probl√®me semble impossible √† r√©soudre : Apple et l'utilisateur ont chacun une liste de NeuralHashs et on cherche √† savoir quels sont ceux qui sont en commun, sans que l'un divulgue √† l'autre la moindre information sur ses propres NeuralHashs. Et pourtant, PSI le fait !

Apple commence par calculer les NeuralHashs des images qui l'int√©ressent, puis les place dans un tableau (sp√©cifiquement une cuckoo table, pour √©viter les collisions). L'index du NeuralHash dans le tableau est calcul√© √† partir de sa valeur uniquement. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524714626224140-E8h56gnXMAMdSDz.jpg" draggable="false">
  </div>
</div>

Ces NeuralHashs sont ensuite masqu√©s (blinded) √† l'aide d'une cl√© d√©tenue par Apple, mais ils gardent leur index dans la table. Les autres index non utilis√©s sont remplis de **hashs al√©atoires**, pour ne pas r√©v√©ler quels sont les index qui int√©ressent Apple. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524718468272129-E8h6CYOXoAsJdKL.jpg" draggable="false">
  </div>
</div>

Ce tableau est transmis aux appareils des utilisateurs. La premi√®re contrainte (ne pas d√©voiler les images recherch√©es) est respect√©e, car l'utilisateur n'a aucun moyen de retrouver les NeuralHashs de la liste d'Apple sans poss√©der √©galement la cl√© de masquage tenue secr√®te.

Pour √©tablir les correspondances entre les photos de l'utilisateur et celles recherch√©es sans conna√Ætre la liste de ces derni√®res, l'utilisateur va en fait envoyer des informations sur TOUTES ses photos, mais Apple ne saura d√©chiffrer **que celles qui correspondent √† sa liste**.

Chacune des photos va donc √™tre trait√©e de la mani√®re suivante : on calcule d'abord une cl√© de chiffrement bas√©e √† la fois sur le NeuralHash de l'image et sur le NeuralHash masqu√© √† l'index associ√© (qui potentiellement ne correspondra pas, si l'image n'est pas dans la base). 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524726013829120-E8h6PldXMAQ-Ck6.jpg" draggable="false">
  </div>
</div>

Cette cl√© nous sert √† chiffrer le duo de {m√©tadonn√©es image + fragment de cl√© des m√©tadonn√©es} dont on parlait au chapitre pr√©c√©dent sur le Threshold Secret Sharing. Ces infos chiffr√©es sont transmises au serveur d'Apple avec une sous-partie de la cl√© du tweet pr√©c√©dent. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524730279387136-E8h6WIpWEAM4WSi.jpg" draggable="false">
  </div>
</div>

Des propri√©t√©s super chouettes des courbes elliptiques permettent √† Apple de reconstituer la cl√© √† partir de la sous-partie qui lui est transmise, √† condition que celle-ci ait bien √©t√© g√©n√©r√©e √† partir d'un NeuralHash et de sa version masqu√©e correspondante. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524734339518468-E8h6brUX0AgGOeS.jpg" draggable="false">
  </div>
</div>

Ainsi, on s'assure de deux choses :

- Le message ne peut √™tre d√©chiffr√© que si le NeuralHash fait aussi partie de la liste d'Apple
- Apple ne peut pas tricher en ajoutant un NeuralHash √† sa liste a posteriori, car le hash masqu√© est pris dans la liste au moment du calcul de cl√©

Pour r√©sumer, le protocole d'Apple est bas√© sur une s√©curit√© √† deux couches : un message ne peut √™tre d√©chiffr√© que si l'image correspond √† un hash recherch√©, et la cl√© permettant de d√©chiffrer les m√©tadonn√©es de ces matchs n'est r√©cup√©r√©e qu'apr√®s N correspondances av√©r√©es.

### EPILOGUE 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524741490847748-E8h6tqvXIAcQbFK.jpg" draggable="false">
  </div>
</div>

On peut cependant relever plusieurs **risques op√©rationnels** sur le protocole propos√© par Apple.

La premi√®re attaque qui me vient √† l'esprit est bas√©e sur des **attaques antagonistes** contre NeuralHash. En effet, il est g√©n√©ralement simple de faire dire ce que l'on veut √† un r√©seau de neurones avec un input malicieux bien calcul√©. 

<div class="gallery-box">
  <div class="gallery">
  <img src="/images/blog/scanning-apple/1425524747522166796-E8h7CLpWYAUvMZn.jpg" draggable="false">
  </div>
</div>

Il suffirait donc de forger des images d'apparence tout √† fait inoffensive qui auraient le m√™me NeuralHash que des images p√©do-pornographiques recherch√©es par Apple, et de les envoyer √† son ennemi jur√© pour d√©clencher une enqu√™te √† son encontre.

Second probl√®me, bien plus important : seul Apple conna√Æt les images qui composent sa base de donn√©es. Qui contr√¥le que ce sont effectivement des contenus p√©do-pornographiques et non des images d'opposition politique ou de contenu pro-LGBT (jug√© ill√©gal dans plusieurs pays) ?

Dans cette m√™me veine, qui garantit que cette liste est **la m√™me pour tout le monde** et qu'un gouvernement autoritaire ne peut pas forcer Apple √† modifier sa liste sous peine de sanctions ?

√Ä mon avis, il est vital d'avoir des observateurs tiers sur ce syst√®me, et il semblerait qu'Apple ne pr√©voit pas cette supervision externe. L'opacit√© de la liste de fichiers offre certes des avantages contre le contournement des filtres, mais c'est aussi un danger.

Pour conclure, la cryptographie du protocole PSI est effectivement un tr√®s bon syst√®me pour assurer la protection de l'enfance sans empi√©ter sur la vie priv√©e (pour relativiser avec la censure de WeChat : [https://citizenlab.ca/2020/05/we...](https://citizenlab.ca/2020/05/we-chat-they-watch/)), mais il est imparfait et manque de garde-fous.

